import { RequestHandler } from "express";
import { initializeDatabase, dbOperations } from "../database";
import {
  API_CONFIG,
  safeFetch,
  getScraperStartUrl,
  buildApiUrl,
  logApiRequest,
  logApiResponse,
  handleApiError,
} from "../../shared/config";
import { safeJson } from "../../shared/safe-parser";

// Note: Safe JSON parsing is now handled by the centralized safeFetch function from shared/config.ts

const pythonBackendUrl = API_CONFIG.BASE_URL;

// Ensure database is initialized (will be called when first route is accessed)
const ensureDatabase = () => {
  try {
    initializeDatabase();
  } catch (error) {
    console.error("Database initialization failed:", error);
  }
};

// Real scraping status with progress tracking
let scrapingStatus = {
  status: "idle", // 'idle', 'running', 'completed', 'error'
  startTime: null as Date | null,
  totalPages: 0,
  currentPage: 0,
  totalItems: 0,
  currentItems: 0,
  progressPercent: 0,
  lastUpdate: new Date(),
  estimatedTimeLeft: 0,
  lastStoppedPage: 0, // Remember where parsing stopped
  scrapingPosition: {
    lastUrl: "",
    lastProcessedId: "",
    totalProcessed: 0,
  },
};

// Activity log for real-time updates (in-memory for quick access)
let activityLog: string[] = [];

// SSE connections for real-time updates
let sseConnections: any[] = [];

// Load recent activities from database on startup
const loadRecentActivities = () => {
  try {
    const activities = dbOperations.getRecentActivities.all(20) as any[];
    activityLog = activities
      .map(
        (activity) =>
          `[${new Date(activity.timestamp).toLocaleTimeString()}] ${activity.message}`,
      )
      .reverse();

    if (activityLog.length === 0) {
      addActivity("Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°");
      addActivity("Ð‘Ð°Ð·Ð° Ð´Ð°Ð½ï¿½ï¿½Ñ… Ñ–Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð°");
      addActivity("API Ð³Ð¾Ñ‚Ð¾Ð²Ðµ Ð´Ð¾ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸");
    }
  } catch (error) {
    console.error("Failed to load activities:", error);
    activityLog = [
      `[${new Date().toLocaleTimeString()}] Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°`,
      `[${new Date().toLocaleTimeString()}] Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð¸Ñ… Ñ–Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð¾Ð²Ð°Ð½Ð°`,
      `[${new Date().toLocaleTimeString()}] API Ð³Ð¾Ñ‚Ð¾Ð²Ðµ Ð´Ð¾ Ñ€Ð¾Ð±Ð¾Ñ‚Ð¸`,
    ];
  }
};

// Activities will be loaded when first needed

// Add activity to log (both memory and database)
const addActivity = (message: string, type: string = "info") => {
  const timestamp = new Date().toLocaleTimeString();
  const logEntry = `[${timestamp}] ${message}`;

  // Add to memory log for quick access
  activityLog.unshift(logEntry);
  if (activityLog.length > 50) activityLog.pop(); // Keep last 50 entries

  // Add to database for persistence
  try {
    dbOperations.insertActivity.run(message, type);
  } catch (error) {
    console.error("Failed to insert activity:", error);
  }

  // Broadcast to SSE connections (Ð±ÑƒÐ´ÐµÐ¼Ð¾ Ð²Ð¸ÐºÐ»Ð¸ÐºÐ°Ñ‚Ð¸ Ð· server/index.ts)
  if ((global as any).broadcastSSE) {
    (global as any).broadcastSSE({
      type: "log",
      message: logEntry,
      timestamp: Date.now(),
    });
  }
};

export const handleStartScraping: RequestHandler = async (req, res) => {
  ensureDatabase();

  try {
    const { listing_type = "sale", max_pages = 10 } = req.body;

    // Validate parameters
    if (max_pages < 1 || max_pages > 50) {
      return res.status(400).json({
        error: "max_pages Ð¼Ð°Ñ” Ð±ÑƒÑ‚Ð¸ Ð¼Ñ–Ð¶ 1 Ñ‚Ð° 50",
        status: "error",
      });
    }

    addActivity(
      `ðŸ”§ FIX: Redirecting to Python FastAPI backend instead of Node spawn`,
    );
    addActivity(
      `ðŸ¤– ÐŸÐžÐ§ÐÐ¢ÐžÐš: Ð ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¹ Botasaurus Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ OLX (${max_pages} ÑÑ‚Ð¾Ñ€Ñ–Ð½Ð¾Ðº, Ñ‚Ð¸Ð¿: ${listing_type})`,
    );
    addActivity(`ðŸ›¡ï¸ Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð°Ð½Ð½Ñ: AntiDetectionDriver + Stealth Ñ€ÐµÐ¶Ð¸Ð¼`);
    addActivity(`ðŸŽ¯ Ð¦Ñ–Ð»ÑŒÐ¾Ð²Ð¸Ð¹ Ñ€ÐµÐ³Ñ–Ð¾Ð½: Ð†Ð²Ð°Ð½Ð¾-Ð¤Ñ€Ð°Ð½ÐºÑ–Ð²ÑÑŒÐº, Ð²Ð°Ð»ÑŽÑ‚Ð°: USD`);

    // Use centralized API configuration
    const pythonBackendUrl = API_CONFIG.BASE_URL;
    const requestUrl = getScraperStartUrl();

    // Prepare request body with validation
    const requestBody = {
      listing_type,
      max_pages: Number(max_pages), // ensure integer
      delay_ms: 5000,
      headful: false,
    };

    addActivity(`ðŸšª Node â†’ Python: POST ${requestUrl}`);
    addActivity(`ðŸ“¦ Request body: ${JSON.stringify(requestBody)}`);
    addActivity(`ðŸ”§ Using centralized API config: ${API_CONFIG.BASE_URL}`);
    addActivity(`â±ï¸ Timeout: ${API_CONFIG.TIMEOUT}ms`);

    // HEALTH-CHECK GATE: ÐŸÐµÑ€ÐµÐ´ ÑÑ‚Ð°Ñ€Ñ‚Ð¾Ð¼ ÑÐºÑ€Ð°Ð¿ÐµÑ€Ð° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÑÑ”Ð¼Ð¾ Ñ‰Ð¾ API Ð¶Ð¸Ð²Ðµ
    addActivity('ðŸ¥ Pre-flight health check...');
    const healthCheck = await safeFetch(`${API_CONFIG.BASE_URL}/health`, {
      method: 'GET'
    });

    if (!healthCheck.ok || healthCheck.status !== 200) {
      const errorMsg = `API Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¸Ð¹ (health check failed): ${healthCheck.error}`;
      addActivity(`âŒ ${errorMsg}`);
      addActivity('ðŸ’¡ Ð Ñ–ÑˆÐµÐ½Ð½Ñ: ÐÐ°Ñ‚Ð¸ÑÐ½Ñ–Ñ‚ÑŒ "Deploy Backend" Ð°Ð±Ð¾ Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€Ñ‚Ðµ https://glow-nest-api.fly.dev/health');

      return res.status(502).json({
        success: false,
        error: 'Python API is not reachable (health check failed)',
        details: {
          health_status: healthCheck.status,
          health_error: healthCheck.error,
          api_url: API_CONFIG.BASE_URL,
          suggestion: 'Deploy backend first or check API connectivity'
        },
        status: 'error'
      });
    }

    addActivity(`âœ… Health check passed: ${healthCheck.data?.status || 'healthy'}`);

    // Use safeFetch for comprehensive error handling
    const fetchResult = await safeFetch(requestUrl, {
      method: "POST",
      body: JSON.stringify(requestBody),
    });

    // Enhanced logging with detailed error diagnostics
    addActivity(
      `ðŸ“¨ Python response: ${fetchResult.status} ${fetchResult.ok ? "OK" : "ERROR"}`,
    );

    if (!fetchResult.ok) {
      const errorMsg = fetchResult.error || "Unknown fetch error";
      const details = fetchResult.details || {};

      // Comprehensive error logging
      addActivity(`âŒ FETCH FAILED: ${errorMsg}`);
      addActivity(`ðŸ” Error type: ${details.name || "Unknown"}`);
      addActivity(`ðŸ“ Error code: ${details.code || "N/A"}`);
      addActivity(
        `ðŸŒ DNS issue: ${details.code === "ENOTFOUND" ? "YES" : "NO"}`,
      );
      addActivity(
        `ðŸ”Œ Connection refused: ${details.code === "ECONNREFUSED" ? "YES" : "NO"}`,
      );
      addActivity(
        `â° Timeout: ${details.code === "ABORT_ERR" || errorMsg.includes("timeout") ? "YES" : "NO"}`,
      );
      addActivity(`ðŸ“ Target URL: ${requestUrl}`);
      addActivity(
        `ðŸ”§ Suggested fixes: Check FastAPI deployment, DNS, firewall, SSL cert`,
      );

      // Log full error details for debugging
      if (details.errno) addActivity(`ðŸ”¢ Error errno: ${details.errno}`);
      if (details.cause)
        addActivity(`ðŸŽ¯ Error cause: ${JSON.stringify(details.cause)}`);

      throw new Error(
        `Python backend fetch failed: ${errorMsg} (${details.code || "Unknown error"})`,
      );
    }

    const pythonResult = fetchResult.data;

    // Log response details for diagnostics
    addActivity(
      `ðŸ“– Response body (first 100 chars): ${fetchResult.text ? fetchResult.text.substring(0, 100) + "..." : "N/A"}`,
    );

    if (!pythonResult?.ok) {
      const errorMsg =
        pythonResult?.error ||
        pythonResult?.detail ||
        `HTTP ${fetchResult.status}`;
      addActivity(`âŒ Python backend error: ${errorMsg}`);
      throw new Error(errorMsg);
    }

    addActivity(
      `âœ… Python backend success: task=${pythonResult.task || "unknown"}`,
    );

    // Update local status for compatibility
    scrapingStatus = {
      status: "running",
      startTime: new Date(),
      totalPages: max_pages,
      currentPage: 0,
      totalItems: 0,
      currentItems: 0,
      progressPercent: 0,
      lastUpdate: new Date(),
      estimatedTimeLeft: max_pages * 30,
      lastStoppedPage: 0,
      scrapingPosition: {
        lastUrl: "",
        lastProcessedId: `python_backend_${Date.now()}`,
        totalProcessed: 0,
      },
    };

    addActivity(
      `âœ… Python backend response: ${pythonResult.message || "Scraping started"}`,
    );
    addActivity(`ðŸ“Š Task ID: ${pythonResult.task || "unknown"}`);
    addActivity(
      `ðŸ• Estimated time: ${pythonResult.estimated_time || "calculating..."}`,
    );
    addActivity(`ðŸ“ Status: ${pythonResult.status || "unknown"}`);
    addActivity(`ðŸšª Node â†’ Admin: Returning success response`);

    res.json({
      success: true,
      message: "Ð ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¹ Botasaurus Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð¾ Ñ‡ÐµÑ€ÐµÐ· Python backend",
      status: "running",
      estimatedTime: `${Math.round((max_pages * 30) / 60)} Ñ…Ð²Ð¸Ð»Ð¸Ð½`,
      progress: 0,
      framework: "Botasaurus v4.0.10+ (Python Backend)",
      features: [
        "AntiDetectionDriver",
        "Stealth Mode",
        "Resume Capability",
        "Real-time Progress",
      ],
      python_backend: true,
      task_id: pythonResult.task_id,
      backend_url: pythonBackendUrl,
    });
  } catch (error) {
    console.error("Error starting scraping via Python backend:", error);
    addActivity(`âŒ ÐŸÐžÐœÐ˜Ð›ÐšÐ Ð·Ð°Ð¿ÑƒÑÐºÑƒ Ñ‡ÐµÑ€ÐµÐ· Python backend: ${error.message}`);

    res.status(500).json({
      success: false,
      error: `ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð¿ÑƒÑÐºÑƒ Ñ‡ÐµÑ€ÐµÐ· Python backend: ${error.message}`,
      status: "error",
    });
  }
};

// Add random property to database with realistic data
const addRandomProperty = () => {
  try {
    // Get random street from database
    const streets = dbOperations.getAllStreetDistricts.all() as any[];
    if (streets.length === 0) {
      console.error("No streets found in database");
      return;
    }

    const randomStreet = streets[Math.floor(Math.random() * streets.length)];
    const isOwner = Math.random() > 0.4; // 60% owners
    const area = Math.floor(Math.random() * 80) + 30; // 30-110 mÂ²
    const basePrice = area * (800 + Math.random() * 800); // $800-1600 per mÂ²
    const rooms = Math.floor(Math.random() * 4) + 1; // 1-4 rooms

    const title = `${rooms}-ÐºÑ–Ð¼Ð½. ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ð° Ð½Ð° Ð²ÑƒÐ». ${randomStreet.street}, ${area}Ð¼Â²`;
    const finalPrice = Math.round(basePrice);
    const floor = Math.floor(Math.random() * 9) + 1;

    // Check if similar property already exists to avoid duplicates
    const existingProperty = dbOperations.checkPropertyExists.get(
      title,
      area,
      randomStreet.street,
      finalPrice,
    ) as { count: number };

    if (existingProperty.count > 0) {
      // Property already exists, skip
      console.log(`Skipping duplicate property: ${title}`);
      return;
    }

    const olxId = `olx_${Date.now()}_${Math.floor(Math.random() * 1000)}`;

    // Insert property into database
    const result = dbOperations.insertProperty.run(
      olxId,
      title,
      finalPrice,
      area,
      rooms,
      floor,
      randomStreet.street,
      randomStreet.district,
      `ÐŸÑ€Ð¾Ð´Ð°Ñ”Ñ‚ÑŒÑÑ ${rooms}-ÐºÑ–Ð¼Ð½Ð°Ñ‚Ð½Ð° ÐºÐ²Ð°Ñ€Ñ‚Ð¸Ñ€Ð° Ð¿Ð»Ð¾Ñ‰ÐµÑŽ ${area}Ð¼Â² Ð½Ð° Ð²ÑƒÐ»Ð¸Ñ†Ñ– ${randomStreet.street} Ð² Ñ€Ð°Ð¹Ð¾Ð½Ñ– ${randomStreet.district}. ${isOwner ? "Ð’Ñ–Ð´ Ð²Ð»Ð°ÑÐ½Ð¸ÐºÐ°." : "Ð§ÐµÑ€ÐµÐ· Ð°Ð³ï¿½ï¿½Ð½Ñ‚ÑÑ‚Ð²Ð¾."}`,
      isOwner ? 1 : 0,
      `https://olx.ua/property/${Math.floor(Math.random() * 100000)}`,
    );

    // Add initial price to history
    if (result.lastInsertRowid) {
      dbOperations.insertPriceHistory.run(
        result.lastInsertRowid,
        olxId,
        finalPrice,
      );
    }
  } catch (error) {
    console.error("Failed to add property:", error);
  }
};

export const handleScrapingStatus: RequestHandler = (req, res) => {
  res.json({
    status: scrapingStatus.status,
    startTime: scrapingStatus.startTime,
    totalPages: scrapingStatus.totalPages,
    currentPage: scrapingStatus.currentPage,
    totalItems: scrapingStatus.totalItems,
    currentItems: scrapingStatus.currentItems,
    progressPercent: scrapingStatus.progressPercent,
    estimatedTimeLeft: scrapingStatus.estimatedTimeLeft,
    lastUpdate: scrapingStatus.lastUpdate,
    isRunning: scrapingStatus.status === "running",
  });
};

export const handlePropertyStats: RequestHandler = (req, res) => {
  ensureDatabase();

  try {
    const stats = dbOperations.getPropertyStats.get() as any;

    res.json({
      totalProperties: stats?.total_properties || 0,
      fromOwners: stats?.from_owners || 0,
      fromAgencies: stats?.from_agencies || 0,
      manualEntries: 0, // TODO: Add manual entries tracking
      lastScraping: stats?.last_update || null,
      ownerPercentage:
        stats?.total_properties > 0
          ? Math.round((stats.from_owners / stats.total_properties) * 100)
          : 0,
      avgPrice: Math.round(stats?.avg_price || 0),
      activityLog: activityLog.slice(0, 10), // Last 10 activities
    });
  } catch (error) {
    console.error("Failed to get property stats:", error);
    res.status(500).json({ error: "Failed to load statistics" });
  }
};

// New endpoint for activity log
export const handleActivityLog: RequestHandler = (req, res) => {
  ensureDatabase();

  // Load recent activities if not already loaded
  if (activityLog.length === 0) {
    loadRecentActivities();
  }

  res.json({
    logs: activityLog,
    last_update: new Date().toISOString(),
  });
};

export const handleStopScraping: RequestHandler = async (req, res) => {
  try {
    // Use centralized API configuration for stop endpoint
    const stopUrl = buildApiUrl(API_CONFIG.ENDPOINTS.SCRAPER_STOP);

    addActivity(`ðŸ›‘ Node â†’ Python: POST ${stopUrl}`);
    addActivity(`ðŸ”§ Using centralized API config: ${API_CONFIG.BASE_URL}`);

    // Use safeFetch for comprehensive error handling
    const fetchResult = await safeFetch(stopUrl, {
      method: "POST",
    });

    addActivity(
      `ðŸ“¨ Python stop response: ${fetchResult.status} ${fetchResult.ok ? "OK" : "ERROR"}`,
    );

    if (!fetchResult.ok) {
      const errorMsg = fetchResult.error || "Unknown fetch error";
      const details = fetchResult.details || {};

      // Enhanced error logging for stop operation
      addActivity(`âŒ STOP FETCH FAILED: ${errorMsg}`);
      addActivity(`ðŸ” Error type: ${details.name || "Unknown"}`);
      addActivity(`ðŸ“ Error code: ${details.code || "N/A"}`);
      addActivity(
        `ðŸŒ DNS issue: ${details.code === "ENOTFOUND" ? "YES" : "NO"}`,
      );
      addActivity(
        `ðŸ”Œ Connection refused: ${details.code === "ECONNREFUSED" ? "YES" : "NO"}`,
      );
      addActivity(
        `â° Timeout: ${details.code === "ABORT_ERR" || errorMsg.includes("timeout") ? "YES" : "NO"}`,
      );
      addActivity(`ðŸ“ Target URL: ${stopUrl}`);

      throw new Error(
        `Python backend stop fetch failed: ${errorMsg} (${details.code || "Unknown error"})`,
      );
    }

    const pythonResult = fetchResult.data;

    if (!pythonResult?.ok) {
      const errorMsg =
        pythonResult?.error ||
        pythonResult?.detail ||
        `HTTP ${fetchResult.status}`;
      addActivity(`âŒ Python backend stop error: ${errorMsg}`);
      throw new Error(errorMsg);
    }

    // Update local status
    scrapingStatus.lastStoppedPage = scrapingStatus.currentPage;
    scrapingStatus.status = "idle";

    // Update database with stopped state
    try {
      dbOperations.updateScrapingState.run(
        scrapingStatus.currentPage,
        scrapingStatus.scrapingPosition?.lastUrl || "",
        scrapingStatus.scrapingPosition?.lastProcessedId || "",
        scrapingStatus.totalItems,
        "idle",
      );
    } catch (error) {
      console.error("Failed to update scraping state on stop:", error);
    }

    addActivity(
      `â¹ï¸ ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð·ÑƒÐ¿Ð¸Ð½ÐµÐ½Ð¾ Ñ‡ÐµÑ€ÐµÐ· Python backend Ð½Ð° ÑÑ‚Ð¾Ñ€Ñ–Ð½Ñ†Ñ– ${scrapingStatus.currentPage}`,
    );
    addActivity(`âœ… Python backend response: ${pythonResult.message}`);

    res.json({
      success: true,
      message: "ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð·ÑƒÐ¿Ð¸Ð½ÐµÐ½Ð¾ Ñ‡ÐµÑ€ÐµÐ· Python backend",
      status: "idle",
      stoppedAt: scrapingStatus.lastStoppedPage,
      python_backend: true,
    });
  } catch (error) {
    console.error("Error stopping scraping via Python backend:", error);
    addActivity(`âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·ÑƒÐ¿Ð¸Ð½ÐºÐ¸ ï¿½ï¿½ÐµÑ€ÐµÐ· Python backend: ${error.message}`);

    res.status(500).json({
      success: false,
      error: `ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·ï¿½ï¿½Ð¿Ð¸Ð½ÐºÐ¸ Ñ‡ÐµÑ€ÐµÐ· Python backend: ${error.message}`,
      status: "error",
    });
  }
};

// Get all properties
export const handleGetProperties: RequestHandler = (req, res) => {
  ensureDatabase();

  try {
    const properties = dbOperations.getAllProperties.all();

    res.json({
      properties: properties.map((p: any) => ({
        id: p.id,
        olx_id: p.olx_id,
        title: p.title,
        price_usd: p.price_usd,
        area: p.area,
        rooms: p.rooms,
        floor: p.floor,
        street: p.street,
        district: p.district,
        description: p.description,
        isOwner: p.is_owner === 1,
        url: p.url,
        created_at: p.created_at,
        last_updated: p.last_updated,
      })),
      total: properties.length,
      last_update: new Date().toISOString(),
    });
  } catch (error) {
    console.error("Failed to get properties:", error);
    res.status(500).json({ error: "Failed to load properties" });
  }
};

// Get street to district mapping
export const handleGetStreetMap: RequestHandler = (req, res) => {
  ensureDatabase();

  try {
    const streets = dbOperations.getAllStreetDistricts.all() as any[];
    const streetMap: { [key: string]: string } = {};

    streets.forEach((street) => {
      streetMap[street.street] = street.district;
    });

    res.json({
      streetMap,
      totalStreets: streets.length,
    });
  } catch (error) {
    console.error("Failed to get street map:", error);
    res.status(500).json({ error: "Failed to load street mapping" });
  }
};

// Add new street to district mapping
export const handleAddStreet: RequestHandler = (req, res) => {
  ensureDatabase();

  const { street, district } = req.body;

  if (!street || !district) {
    return res.status(400).json({
      error: "ÐŸÐ¾Ñ‚Ñ€Ñ–Ð±Ð½Ñ– Ð½Ð°Ð·Ð²Ð° Ð²ÑƒÐ»Ð¸Ñ†Ñ– Ñ‚Ð° Ñ€Ð°Ð¹ï¿½ï¿½Ð½",
    });
  }

  try {
    // Check if street already exists
    const existing = dbOperations.getDistrictByStreet.get(street) as any;
    if (existing) {
      return res.status(400).json({
        error: `Ð’ÑƒÐ»Ð¸Ñ†Ñ "${street}" Ð²Ð¶Ðµ Ñ–ÑÐ½ÑƒÑ” Ð² Ñ€Ð°Ð¹Ð¾Ð½Ñ– "${existing.district}"`,
      });
    }

    // Insert new street
    dbOperations.insertStreetDistrict.run(street, district);
    addActivity(`Ð”Ð¾Ð´Ð°Ð½Ð¾ Ð²ÑƒÐ»Ð¸Ñ†ÑŽ "${street}" Ð´Ð¾ Ñ€Ð°Ð¹Ð¾Ð½Ñƒ "${district}"`);

    res.json({
      message: `Ð’ÑƒÐ»Ð¸Ñ†ÑŽ "${street}" ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð´Ð¾Ð´Ð°Ð½Ð¾ Ð´Ð¾ Ñ€Ð°Ð¹Ð¾Ð½Ñƒ "${district}"`,
    });
  } catch (error) {
    console.error("Failed to add street:", error);
    res.status(500).json({ error: "ÐŸÐ¾Ð¼Ð¸Ð»ï¿½ï¿½Ð° Ð´Ð¾Ð´Ð°Ð²Ð°Ð½Ð½Ñ ï¿½ï¿½ÑƒÐ»Ð¸Ñ†Ñ–" });
  }
};

// Check for property updates (price changes)
export const handleCheckPropertyUpdates: RequestHandler = (req, res) => {
  ensureDatabase();

  try {
    // Get all properties from database
    const properties = dbOperations.getAllProperties.all() as any[];
    const updatedProperties: any[] = [];

    properties.forEach((property) => {
      // Simulate 10% chance of price change
      if (Math.random() < 0.1) {
        const oldPrice = property.price_usd;
        const priceChange = (Math.random() - 0.5) * 0.2; // Â±10% change
        const newPrice = Math.round(oldPrice * (1 + priceChange));

        // Update price in database
        dbOperations.updatePropertyPrice.run(newPrice, property.olx_id);

        // Add to price history
        dbOperations.insertPriceHistory.run(
          property.id,
          property.olx_id,
          newPrice,
        );

        updatedProperties.push({
          olx_id: property.olx_id,
          title: property.title,
          oldPrice,
          newPrice,
          change: newPrice - oldPrice,
          changePercent: Math.round(((newPrice - oldPrice) / oldPrice) * 100),
        });
      }
    });

    if (updatedProperties.length > 0) {
      addActivity(`Ð—Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ ${updatedProperties.length} Ð¾Ð½Ð¾ï¿½ï¿½Ð»ÐµÐ½ÑŒ Ñ†Ñ–Ð½`);
    }

    res.json({
      updatedProperties,
      totalChecked: properties.length,
      updatesFound: updatedProperties.length,
      lastCheck: new Date().toISOString(),
    });
  } catch (error) {
    console.error("Failed to check property updates:", error);
    res.status(500).json({ error: "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð¿ÐµÑ€ÐµÐ²Ñ–Ñ€ÐºÐ¸ Ð¾Ð½Ð¾Ð²Ð»ÐµÐ½ÑŒ" });
  }
};

// Generate price trends based on real data
export const handlePriceTrends: RequestHandler = (req, res) => {
  ensureDatabase();

  try {
    const properties = dbOperations.getAllProperties.all() as any[];

    // Only show data if we actually have scraped properties
    if (properties.length === 0) {
      return res.json({
        monthly_trends: [],
        top_streets: [],
        total_properties: 0,
        last_update: new Date().toISOString(),
        message:
          "ÐÐµÐ¼Ð°Ñ” Ð´Ð°Ð½Ð¸Ñ… Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ. Ð—Ð°Ð¿ÑƒÑÑ‚Ñ–Ñ‚ÑŒ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³ Ð´Ð»Ñ Ð·Ð±Ð¾Ñ€Ñƒ Ð¾Ð³Ð¾Ð»Ð¾ÑˆÐµÐ½ÑŒ.",
      });
    }

    // Group properties by actual dates when they were scraped
    const propertiesByDate: { [key: string]: any[] } = {};

    properties.forEach((property) => {
      const date = new Date(property.created_at);
      const dateKey = `${date.getFullYear()}-${String(date.getMonth() + 1).padStart(2, "0")}-${String(date.getDate()).padStart(2, "0")}`;

      if (!propertiesByDate[dateKey]) {
        propertiesByDate[dateKey] = [];
      }
      propertiesByDate[dateKey].push(property);
    });

    // Generate trends only for dates that actually have data
    const trends = Object.entries(propertiesByDate)
      .sort(([dateA], [dateB]) => dateA.localeCompare(dateB))
      .map(([dateKey, properties]) => {
        const date = new Date(dateKey);
        const avgPrice = Math.round(
          properties.reduce((sum, p) => sum + p.price_usd, 0) /
            properties.length,
        );
        const avgArea = Math.round(
          properties.reduce((sum, p) => sum + p.area, 0) / properties.length,
        );

        return {
          date: dateKey,
          month: date.toLocaleDateString("uk-UA", {
            day: "numeric",
            month: "long",
          }),
          count: properties.length,
          avg_price: avgPrice,
          price_per_sqm: Math.round(avgPrice / avgArea),
          total_volume: properties.length * avgPrice,
        };
      });

    // Calculate top streets with real data
    const streetCounts: {
      [key: string]: { count: number; totalPrice: number; avgArea: number };
    } = {};

    properties.forEach((property) => {
      const street = property.street || "Ð†Ð½ÑˆÑ– Ð²ÑƒÐ»Ð¸Ñ†Ñ–";

      if (streetCounts[street]) {
        streetCounts[street].count++;
        streetCounts[street].totalPrice += property.price_usd;
        streetCounts[street].avgArea += property.area;
      } else {
        streetCounts[street] = {
          count: 1,
          totalPrice: property.price_usd,
          avgArea: property.area,
        };
      }
    });

    const topStreets = Object.entries(streetCounts)
      .map(([street, data]) => ({
        street,
        count: data.count,
        avg_price: Math.round(data.totalPrice / data.count),
        avg_area: Math.round(data.avgArea / data.count),
      }))
      .sort((a, b) => b.count - a.count)
      .slice(0, 5);

    res.json({
      monthly_trends: trends,
      top_streets: topStreets,
      total_properties: properties.length,
      last_update: new Date().toISOString(),
    });
  } catch (error) {
    console.error("Failed to generate price trends:", error);
    res.status(500).json({ error: "ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ñ–Ñ— Ñ‚Ñ€ÐµÐ½Ð´Ñ–Ð²" });
  }
};
